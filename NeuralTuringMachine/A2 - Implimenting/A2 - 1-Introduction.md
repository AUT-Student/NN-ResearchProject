# پاراگراف اول
![[Pasted image 20220630092948.png]]

NTM ‌ها یکی از نمونه‌‌های چندین معماری جدید شبکه عصبی جدید هستند که در دسته شبکه‌های عصبی حافظه‌دار قرار می‌گیرند. ویژگی تعریف‌کننده شبکه‌های عصبی حافظه‌دار وجود یک واحد حافظه خارجی است. این در تضاد با شبکه‌های عصبی دروازه‌دار (Gated RNN) نظیر LSTM است که حافظه به عنوان یک بردار داخلی در طول زمان است. LSTM‌ها بهترین نتایج را در وظایف آموزش ترتیبی بدست آورده‌اند؛ به عنوان مثال در شناسایی دست‌خط، ترجمه ماشینی و شناسایی صوت. اما شبکه‌های عصبی حافظه‌دار در برخی از وظایف یادگیری ترتیبی مصنوعی که نیاز به حافظه زیاد داشته است و یا اینکه الگوهای پیچیده‌تری از دسترسی به حافظه نظیر دنباله‌های بلند یا پیمایش گراف نیاز داشته است توانست است نتایج بهتری از LSTM بگیرد.

# پاراگراف دوم
![[Pasted image 20220630094922.png]]
![[Pasted image 20220630094946.png]]
مولفین مقاله NTM کدی برای پیاده‌سازی‌شان ارائه نکرده‌اند. پیاده‌سازی‌های منبع‌بازی از NTM‌وجود دارد اما یک تعدادی از آن‌ها گزارش کرده‌اند که گرادیان‌های پیاده‌سازی‌شان برخی مواقع NaN می‌شود و نهایتا آموزش شکست می‌خورد. درحالی که برخی دیگر سرعت پایین همگرایی را گزارش کرده‌اند یا اصلا سرعت یادگیری پیاده‌سازی خود را بیان نکرده‌اند.

به دلیل نبود پیاده‌سازی منبع‌باز پایدار از NTM امکان اعمال NTM بر مسائل جدید و برای بهبود آن توسط محقیق دشوار خواهد بود.

# پاراگراف سوم
![[Pasted image 20220630095435.png]]
در این مقاله ما یک پیاده‌سازی موفق از NTM ارائه کرده‌ایم که برای وظیفه یادگیری ترتیبی را حل می‌کند. ما یک مقایسه عملی از تعدادی از برنامه‌های مقداردهی اولیه محتوای حافظه که در سایر پیاده‌سازی‌های منبع‌باز NTM معرفی‌شده است انجام داده‌ایم. ما فهمیده‌ایم که کلید موفقیت پیاده‌سازی NTM‌در چگونگی مقداردهی اولیه محتوای حافظه است.

ما پیاده‌سازی تنسورفلوی خود را بر پایه یکی دیگر از پیاده‌سازی‌های منبع‌باز قرار داده‌ایم اما نتایج پیاده‌سازی ما نشان از بهبود قابل ملاحظه‌ای بر روی مقداردهی اولیه محتوای حافظه، محاسبه پارامتر‌های سر کنترل‌گر و رابط (Interface) داشته است که باعث همگرایی سریع‌تر، بهینه‌سازی مطمئن‌تر و ادغام ساده‌ار با روش‌های تسورفلوی موجود می‌شود.

پیاده‌سازی ما تحت یک لایسنس منبع‌باز منتشر شده است.