# پاراگراف اول
![[Pasted image 20220630100914.png]]

NTM‌ شامل دو جز است:
* کنترل‌گر شبکه که می‌تواند یک شبکه‌عصبی جلورو یا یک شبکه عصبی بازگشتی باشد
* یک واحد حافظه خارجی که یک ماتریس حافظه N×W است. N تعداد واحد‌های حافظه و W ابعاد هر سلول حافظه را نمایش می‌دهد.

فارغ از آنکه کنترل‌گر بازگشتی باشد یا خیر، کل معماری بازگشتی محسوب می‌شود چراکه ماتریس حافظه در طول زمان نگهداری می‌شود.

کنترل‌گر سرهای خوانده و نوشتن دارد که به ماتریس حافظه دسترسی دارد. تاثیر یک عمل خواندن یا نوشتن روی یک سلول حافظه خاص با مکانیسم توجه نرم (Soft Attention Mechanism) وزن‌دهی می‌شود. این مکانیسم آدرس‌دهی مشابه مکانیسم توجه استفاده‌شده در یادگیری ماشین عصبی است به جز آنکه آدرس‌دهی وابسته به موقعیت را با آدرس‌دهی وابسته به محتوای موجود در مکانیسم توجه  را ترکیب می‌کند.

# پاراگراف دوم (فرمول‌ها)
![[Pasted image 20220630102240.png]]
به طور خاص برای یک NTM در هر گام زمانی (t) برای هر سر خواندن و نوشتن کنترل‌گر یک تعدادی پارامتر را به عنوان خروجی می‌دهد: <در بالا> این پارامتر‌ها استفاده می‌شوند تا وزن $w_t$ برای موقعیت‌های N حافظه در ماتریس حافظه $M_t$ مطابق فرمول ۱ محاسبه کند.

![[Pasted image 20220630102728.png]]
$k_t$ یک کلید جستجو در حافظه را نشان می‌دهد و $K$ مطابق رابطه ۲ یک معیار شباهت مانند شباهت کسینوسی است. $w_t^c$ امکان آدرس‌دهی وابسته به محتوا را فراهم می‌کند.

![[Pasted image 20220630112547.png]]
با یک سری از محاسبات، NTM‌ها امکان تکرار بر روی وزن‌های حافظه فعلی و قبلا محاسبه‌شده را خواهند داشت: رابطه ۳، ۴ و ۵

رابطه ۳ به شبکه اجازه می‌دهد تا بین بردار وزن قبلی یا فعلی انتخاب کند که از کدام استفاده کند.
رابطه ۴ امکان تکرار از طریق حافظه با کانوالو کردن وزن فعلی و یک کرنل کانوولوشنی شیفت یک بعدی را فراهم می‌کند.
رابطه ۵ رخداد تارشدن (Blurring) که به واسطه عمل کانوولوشن رخداده است را اصلاح می‌کند.

![[Pasted image 20220630113200.png]]
بردار $r_i$ به وسیله‌ی یک سر خواندن خاص در زمان t محاسبه می‌گردد: رابطه ۶

هر سر نوشتن ماتریس حافظه را در گام t با محاسبه بردارهای جانبی پاک‌کردن ($e_t$) و جمع‌ ($a_t$) تغییر می‌دهد: رابطه ۷ و رابطه ۸

# پاراگراف سوم
![[Pasted image 20220630114619.png]]
روابط ۱ تا ۸ چگونگی محاسبه و استفاده از عمل خواندن از و نوشتن به حافظه را در یک NTM تعریف می‌کنند اما جزئیات پیاده‌سازی یک NTM باز است. به طور خاص انتخاب معیار شباهت $K$، مقادیر اولیه وزن‌دهی $w_0$ برای تمام سرهای خواندن و نوشتن، وضعیت اولیه ماتریس حافظه $M_0$، انتخاب تابع غیرخطی که بر پارامترهای خروجی هر سر خواندن و نوشتن اعمال می‌شود و مقادیر اولیه تابع خواندن $r_0$ تماما در NTM تعریف نشده است.


# پاراگراف چهارم
![[Pasted image 20220630114637.png]]
هر انتخابی که محدودیت پارامتر‌های خروجی کنترل‌گر را برآورده کند، یک NTM معتبر خواهد بود. در عمل این انتخاب‌ها تاثیر مهمی بر توانایی NTM برای یادگیری دارد.
