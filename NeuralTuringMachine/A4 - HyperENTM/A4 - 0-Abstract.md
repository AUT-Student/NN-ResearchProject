![[Pasted image 20220630202546.png]]
توسعه اخیر شبکه‌های عصبی حافظه‌دار مسائل ترتیبی که نیازمند حافظه طولانی‌مدت هستند و با شبکه‌های عصبی سنتی قابل حل نبوده‌اند را حل کرده است.  اگرچه روش‌های فعلی هنوز برای حافظه‌های با اندازه بالا و دنباله‌های طولانی مقیاس‌پذیر نیستند.

در این مقاله ما نشان داده‌ایم که چگونه دسترسی به حافظه می‌توان به شکل هندسی از طریق یک ماشین تورینگ عصبی برپایه HyperNEAT (Hyper-ENTM) کد شود. ما نشان دادیم که استفاده غیرمستقیم از کدکردن HyperNEAT امکان آموزش بر روی بردارهای حافظه کوچک در یک وظیفه رونوشت‌گیری فراهم می‌کند و سپس دانش کسب‌شده از چنین آموزشی باعث تسریع آموزش بر روی بردارهای حافظه با اندازه زیاد می‌شود.

![[Pasted image 20220630203629.png]]
به علاوه ما نشان دادیم که در برخی از موارد شبکه آموزش‌یافته برای رونوشت‌گیری از بردارهای بیتی با اندازه ۹ می‌تواند تا اندازه ۱۰۰۰ بدون آموزش اضافه افزایش مقیاس پیدا کند. اگرچه چنین تسکی در روی کاغذ ساده است اما این نتایج می‌تواند مسائل قابل اصلاح برای شبکه‌های با حافظه خارجی که مربوط به مشکلات بردارهای حافظه بزرگ‌تر و از لحاظ تئوری نامحدود هستند را بازکند.